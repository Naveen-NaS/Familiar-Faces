# -*- coding: utf-8 -*-
"""Person_Classification_Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JSXxFsLi1OQLHi7KlRUMJhvi4b3A_WnN

## Importing Libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import cv2
import matplotlib
from matplotlib import pyplot as plt
# %matplotlib inline

"""## Image Pre-processing"""

img = cv2.imread('./test_images/naveen1.jpg')
img.shape

plt.imshow(img)

gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
gray.shape

gray

plt.imshow(gray, cmap='gray')

face_cascade = cv2.CascadeClassifier('./opencv/haarcascades/haarcascade_frontalface_default.xml')
eye_cascade = cv2.CascadeClassifier('./opencv/haarcascades/haarcascade_eye.xml')

faces = face_cascade.detectMultiScale(gray, 1.3, 5)
faces

(x,y,w,h) = faces[0]
x,y,w,h

face_img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),4)
plt.imshow(face_img)

cv2.destroyAllWindows()
for (x,y,w,h) in faces:
    face_img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
    roi_gray = gray[y:y+h, x:x+w]
    roi_color = face_img[y:y+h, x:x+w]
    eyes = eye_cascade.detectMultiScale(roi_gray)
    for (ex,ey,ew,eh) in eyes:
        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)


plt.figure()
plt.imshow(face_img, cmap='gray')
plt.show()

"""### Croping Final image"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
plt.imshow(roi_color, cmap='gray')

cropped_img = np.array(roi_color)
cropped_img.shape

"""### Wavelet transform"""

# Getting various facial features such as eyes, nose, lips etc using "Wavelet transform"
import pywt

def w2d(img, mode='haar', level=1):
    imArray = img
    #Datatype conversions
    #convert to grayscale
    imArray = cv2.cvtColor( imArray,cv2.COLOR_RGB2GRAY )
    #convert to float
    imArray =  np.float32(imArray)
    imArray /= 255;
    # compute coefficients
    coeffs=pywt.wavedec2(imArray, mode, level=level)

    #Process Coefficients
    coeffs_H=list(coeffs)
    coeffs_H[0] *= 0;

    # reconstruction
    imArray_H=pywt.waverec2(coeffs_H, mode);
    imArray_H *= 255;
    imArray_H =  np.uint8(imArray_H)

    return imArray_H

im_har = w2d(cropped_img,'db1',5)
plt.imshow(im_har, cmap='gray')

"""## Saving final croped image"""

def get_cropped_image(image_path):
    img = cv2.imread(image_path)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray, 1.3, 5)
    for (x,y,w,h) in faces:
        roi_gray = gray[y:y+h, x:x+w]
        roi_color = img[y:y+h, x:x+w]
        eyes = eye_cascade.detectMultiScale(roi_gray)
        if len(eyes) >= 1:
            return roi_color

original_image = cv2.imread('./test_images/naveen1.jpg')
plt.imshow(original_image)

cropped_image = get_cropped_image('./test_images/naveen1.jpg')
plt.imshow(cropped_image)

"""### Testing on unclear data"""

org_unclear_image = cv2.imread('./test_images/naveen2.jpg')
plt.imshow(org_unclear_image)

unclear_cropped_image = get_cropped_image('./test_images/naveen2.jpg')
unclear_cropped_image

"""## Saving Cropped Image to new dir"""

path_to_data = "./Dataset/"
path_to_cr_data = "./Dataset/CROPPED/"

import os
img_dirs = []
for entry in os.scandir(path_to_data):
    if entry.is_dir():
        img_dirs.append(entry.path)

img_dirs

import shutil
if os.path.exists(path_to_cr_data):
     shutil.rmtree(path_to_cr_data)
os.mkdir(path_to_cr_data)

cropped_image_dirs = []
person_file_names_dict = {}
for img_dir in img_dirs:
    count = 1
    person_name = img_dir.split('/')[-1]
    person_file_names_dict[person_name] = []
    for entry in os.scandir(img_dir):
        roi_color = get_cropped_image(entry.path)
        if roi_color is not None:
            cropped_folder = path_to_cr_data + person_name
            if not os.path.exists(cropped_folder):
                os.makedirs(cropped_folder)
                cropped_image_dirs.append(cropped_folder)
                print("Generating cropped images in folder: ",cropped_folder)
            cropped_file_name = person_name + str(count) + ".png"
            cropped_file_path = cropped_folder + "/" + cropped_file_name
            cv2.imwrite(cropped_file_path, roi_color)
            person_file_names_dict[person_name].append(cropped_file_path)
            count += 1

class_dict = {}
count = 0
for person_name in person_file_names_dict.keys():
    class_dict[person_name] = count
    count = count + 1
class_dict

"""### Splitting of Dataset"""

X, y = [], []
for person_name, training_files in person_file_names_dict.items():
    for training_image in training_files:
        img = cv2.imread(training_image)
        scalled_raw_img = cv2.resize(img, (32, 32))
        img_har = w2d(img,'db1',5)
        scalled_img_har = cv2.resize(img_har, (32, 32))
        combined_img = np.vstack((scalled_raw_img.reshape(32*32*3,1),scalled_img_har.reshape(32*32,1)))
        X.append(combined_img)
        y.append(class_dict[person_name])

len(X[0])

X[0]

y[0]

X = np.array(X).reshape(len(X),4096).astype(float)
X.shape

"""## Model Training"""

from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)

pipe = Pipeline([('scaler', StandardScaler()), ('svc', SVC(kernel = 'rbf', C = 10))])
pipe.fit(X_train, y_train)
pipe.score(X_test, y_test)

print(classification_report(y_test, pipe.predict(X_test)))

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, pipe.predict(X_test))
cm

import seaborn as sn
plt.figure(figsize = (10,7))
sn.heatmap(cm, annot=True)
plt.xlabel('Predicted')
plt.ylabel('Truth')

# Finding best model using grid search

"""## Testing Model on new oputput"""

def preprocess_image(img_path):
    # Read the image
    img = cv2.imread(img_path)

    # Resize the image
    scalled_raw_img = cv2.resize(img, (32, 32))

    # Apply wavelet transform
    img_har = w2d(img, 'db1', 5)
    scalled_img_har = cv2.resize(img_har, (32, 32))

    # Combine the features
    combined_img = np.vstack((scalled_raw_img.reshape(32*32*3, 1), scalled_img_har.reshape(32*32, 1)))

    return combined_img.T

single_image_path = "./Dataset/chaitanya_gupta/img2.jpg"
single_image = preprocess_image(single_image_path)

# Make prediction using the pre-trained model 'pipe'
prediction = pipe.predict(single_image)

print("Predicted class:", prediction)